\chapter{Übersicht}
\label{sec:uebersicht}

In diesem Kapitel werden die Grundstruktur von MP3-Dateien und die
Grund\-züge ihrer Kodierung und Dekodierung erläutert. Anschliessend
wird die Problematik des Versendens von MP3-Daten über ein
paketorientiertes Netzwerk beschrieben. Schliesslich werden mehrere
Sendeverfahren sowie ihre Vor- und Nachteile vorgestellt.

\section{Struktur und Kodierung von MP3}
\label{sec:mp3-structure}

In den ISO-Standards 11172-3 und 13818-3 wird das MPEG-Audio-Format
beschrieben, welches als MPEG-1-Standard (für Abtastraten von 32, 44.1
und 48 kHz), als MPEG-2-Standard (für 16, 22.05 und 24 kHz Abtastraten
und Mehrkanalkodierung) und als MPEG-2.5-Standard (für 8 und 11 kHz
Abtastraten) existiert. Jeder dieser drei Standards definiert drei
Ebenen (\emph{Layer}).  Jede Ebene ist abwärtskompatibel,
d.h., dass ein Layer 2-Dekoder auch Layer 1 entschlüsseln können
muss. Bei Layer 3 werden die Audiodaten zusätzlich transformiert und
Huffman kodiert. Alle drei Layer und MPEG-Standards sind jedoch in
vielen Hinsichten ähnlich.

Wir befassen uns in dieser Arbeit mit dem sogenannten MP3-Format, d.h.
mit dem MPEG-Audio Layer-3-Format, unter dem sowohl MPEG-1-Layer-3 als
auch MPEG-2 Layer-3, unter Umständen auch das selten benutzte
MPEG-2.5 Layer-3-Format zusammengefasst sind. Die meisten MP3-Dateien
sind MPEG-1 Layer-3-Dateien.

\subsection{MP3-Kodierung}

Der MPEG-Standard legt fest, wie ein MP3-Dekodierer Audiodaten im
MP3-Format entkomprimieren und abspielen soll. Das Verfahren der
MP3-Kodierung wird jedoch nur grob beschrieben: Es ist jeder
Implementierung überlassen, welche genauen Verfahren benutzt werden.

\begin{figure}[htbp]
  \centering
  \includegraphics[scale=0.43]{mp3-kodierung3}
  \caption{MP3-Kodierungsverfahren}
  \label{gra:mp3-kodierung}
\end{figure}

Das MP3-Kodierungsverfahren besteht meistens aus 3 Phasen (siehe
Abbildung \ref{gra:mp3-kodierung}):
\begin{enumerate}
\item Als erstes wird eine feste Anzahl an Audiodaten
  (PCM-Audiosamples) der Quelle gefiltert und transformiert. Bei Layer
  1 und Layer 2 werden 384 Samples eingelesen, bei Layer 3 1152
  Samples. Diese Eingangssamples werden durch eine Filterbank in 32
  Fre\-quenz\-bänder aufgeteilt. Bei Layer 1 und Layer 2 ist dies
  eine einfache Filterbank, bei Layer 3 wird sie durch eine
  hybride Filterbank ersetzt: Die 32 Fre\-quenz\-bänder werden weiter
  durch eine modifizierte diskrete Kosinustransformation in 18 feinere
  Bänder aufgeteilt, um Redundanzverzerrungen (Maskierungseffekte an
  den Grenzen von Fre\-quenz\-bändern) zu vermeiden.
  
\item An Hand dieser transformierten Audiodaten kann der Kodierer mit
  Hilfe eines psychoakustischen Modells bestimmen, wie wichtig
  einzelne Fre\-quenz\-bänder sind und somit welche Informationsmenge
  ihnen zuzuordnen ist, d.h. mit welcher Auflösung sie quantisiert
  werden sollen. Ab Layer 2 kann zu jedem Fre\-quenzband ein
  Skalierungsfaktor angegeben werden, um die Quantisierungsauflösung
  anzupassen. Generell werden grössere Werte gröber kodiert, kleinere
  Werte dafür mit höherer Auflösung.  Bei Layer 3 werden die
  Audiodaten anschliessend Huffman-kodiert. Für die Kodierung werden
  Huffman-Tabellen benutzt, die für bestimmte Werteverteilungen
  angepasst sind.
  
  Dieses Verfahren wird iterativ durchgeführt, bis ein annehmbarer
  Kompromiss zwischen Qualität und Informationsmenge gefunden wurde.
  In einer äusseren Schleife wird jedem Fre\-quenzband ein
  Quantifisierungsfaktor zugewiesen, der solange angepasst wird, bis
  sich das Quantisierungsrauschen unter der Grenze befindet, die durch
  das psychoakustische Modell des Kodierers gesetzt wurde. In einer
  inneren Schleife werden den Audiowerten Huffman-Kodewörter
  zugewiesen. Wenn die sich daraus ergebende Bitmenge zu groß ist,
  werden Quantisierung und Skalierung angepasst. Diese Schleifen
  werden solange durchgelaufen, bis der Quantisierungsfaktor aller
  Fre\-quenz\-bänder angepasst wurde und die resultierende
  Informationsmenge nicht grösser als die vorgegebene Bitrate ist.

  Alternativ zu einer festen Ausgangsbitrate kann auch eine variable
  Bitrate benutzt werden. In diesem Fall wird je nach Komplexität der
  vorliegenden Audiodaten eine andere Ausgangsbitrate ausgewählt, um
  eine feinere Quantisierung der Audiodaten zu ermöglichen.
  
\item Nachdem für jedes Fre\-quenzband eine angemessene Quantisierung
  und Kodierung gefunden wurde, müssen die kodierten Audiodaten in
  MP3-Frames verpackt werden, damit sie gespeichert und übertragen
  werden können. Jedem Frame wird ein Header vorangestellt,
  der die Dekodierungsinformation enthält. Das Format des Headers und
  des MP3-Frames wird in dem MP3-Standard bitgenau beschrieben (siehe
  Abschnitt \ref{sec:transcoding}).
\end{enumerate}

\subsection{MP3-Dekodierung}

Das MP3-Dekodierungsverfahren besteht aus der Umkehrung der
Kodierungsschritte, wobei das psychoakustische Analysieren der Eingangsdaten
entfällt. Die nötigen Huffmann-Tabellen und Filterkoeffizienten sind
im MP3-Standard festgelegt.
\begin{enumerate}
\item Das anstehende MP3-Frame wird eingelesen und die
  Kodierungsinformationen aus dem Frame-Header extrahiert. An Hand
  dieser Informationen werden die Audiodaten eingelesen.
\item Bei Layer 3 müssen die komprimierten Daten
  erst Huffman-dekodiert werden. Aus der Headerinformation wird
  ermittelt, welche Huffman-Tabellen benutzt werden sollen.
\item Anschliessend werden die quantisierten und skalierten Daten
  wieder hergestellt. Die vorliegenden Audiodaten werden durch inverse
  Transformation durch eine synthetisierende Filterbank (bei Layer 3
  noch durch inverse modifizierte diskrete Kosinustransformation) zu
  einem PCM-Signal zurückgewandelt.
\end{enumerate}

\subsection{Bit-Reservoir}

Es kann vorkommen, dass ein MP3-Frame sich in weniger Bits als durch
die vorgegebene Bitrate kodieren lässt. In diesem Fall werden die
unbenutzten Bits in das sogenannte ``Bit-Reservoir'' (siehe Abbildung
\ref{pic:bit-reservoir}) gespeichert.  Lässt sich umgekehrt ein
MP3-Frame nicht ohne Zusatzinformation angemessen kodieren, kann der
Kodierer zusätzliche Bits aus dem Bit-Reservoir verwenden.

\begin{figure}[htbp]
  \centering
  \includegraphics[scale=0.43]{bit-reservoir2}
  \label{pic:bit-reservoir}
  \caption{Bit Reservoir}
\end{figure}

Das Bit-Reservoir wird nicht getrennt gespeichert, sondern direkt in
den MP3-Strom eingefügt. Das hat zur Folge, dass MP3-Frames nicht mehr
alle zu dem Frame-Header gehörende Audiodaten beinhalten. Der Anfang
der eigentlichen Audiodaten wird durch einen Verweis auf frühere Daten
im Strom gegeben (der ``Backpointer''). So kann es vorkommen, dass die
eigentlichen Audiodaten eines MP3-Frames bis zu 9 Frames zurück
liegen.

\section{MP3-Streaming}
\label{sec:mp3-streaming}

\subsection{Streaming}

Bei dem Streaming von MP3-Daten werden die Audiodaten als
kontinuierlicher Datenstrom über das Netzwerk gesendet, ähnlich wie
bei herkömmlichen Rundfunkverfahren. Dadurch kann der Benutzer schon
während der Übertragung der Daten den Inhalt abspielen. Es ist weiterhin
möglich, mehreren Empfän\-gern denselben Datenstrom zukommen zu lassen
(``Multicast''), um somit Bandbreite und Netzwerktraffic zu sparen.
Die Netzwerkprogramme (Clients und Server), die im Rahmen dieser
Studienarbeit implementiert wurden, lassen sich sowohl als Unicast-
als auch als Multicastprogramme benutzen (bis auf den HTTP-Streaming
Server).

Das MP3-Format ist für Streaming gut geeignet, da zu dem Entschlüsseln
eines MP3-Stromes keine früheren Daten notwendig sind (abgesehen vom
Bit-Reservoir). Anders als bei anderen Komprimierungsverfahren, wie
z.B. LZW, ist es nicht notwendig, den Datenstrom von Anfang an zu
entschlüsseln.

\subsubsection{Verfahren}
\label{sub:verfahren}

Wir beschränken uns in dieser Arbeit auf ein IP-basiertes Netzwerk.
Die meisten Konzepte lassen sich jedoch auf andere paketorientierte
Netzwerkprotokolle übertragen.


Audiodaten können bei IP-Netzwerken in zwei Weisen übertragen werden:
 \begin{itemize}
 \item Mit dem TCP-Protokoll können Daten verlustfrei übertragen
   werden. Korrekt empfangene Pakete (mit korrekter Prüfsumme) werden
   vom Empfän\-ger quittiert. Geht allerdings ein Paket verloren,
   entfällt diese Quittierung, und der Sender sendet das Paket erneut.
   Somit wird gewährleistet, dass keine Daten verloren gehen.  Pakete,
   die in falscher Reihenfolge am Ziel ankommen, werden entweder
   verworfen oder umgeordnet. Dieses automatische Neusenden von
   verlorenen Paketen führt allerdings zu Verzö\-ge\-rungen in dem
   Datenstrom.  Bei TCP wird mehr Wert auf die Aufrechterhaltung einer
   kontinuierlichen und verlustlosen Verbindung gelegt, als auf die
   zeitlich nahe Auslieferung der einzelnen Pakete. Es besteht auch
   das Problem, dass TCP nicht für Situationen geeignet ist, an der
   mehrere Empfän\-ger teilnehmen (Broadcast, Multicast).
 \item Mit dem UDP-Protokoll können Daten als Datagramme fehlerfrei
   versendet werden. Allerdings wird nur gewährleistet, dass
   empfangene Pakete korrekt sind; nicht, dass sie am Ziel
   ankommen, und auch nicht, dass sie in der richtigen Reihenfolge
   empfangen werden. Gerade wegen diesem Verzicht auf eine
   verlustfreie End-zu-End-Verbindung ist UDP gut geeignet als
   Transportprotokoll für Multicastanwendungen. Ein weiterer Vorteil
   von UDP ist die kleinere Paketheaderlänge von 8 Bytes, mit der sich
   Audiodaten effizienter versenden lassen.
\end{itemize}
% TCP, UDP, RTP, RTSP

Auf diesen zwei grundlegenden Protokollen bauen weitere Protokolle auf:
\begin{itemize}
  % RFCS für HTTP
\item HTTP ist ein auf TCP aufbauendes Anfrage/Antwort Protokoll, dass
  haupt\-sächlich zur Übermittlung von Webseiten benutzt wird. HTTP hat
  sich auch als MP3-Streaming Protokoll durchgesetzt.  Allerdings
  gelten hier genau dieselben Einschränkungen wie für TCP, nämlich
  dass sich das zeitliche Verhalten der Übertragung der Audiodaten
  sehr schlecht ein\-schä\-tzen lässt, und das HTTP nicht für
  Multicastanwendungen (wie z.B. Internetradio) geeignet ist, da der
  Audiostream zu jedem Empfän\-ger erneut versendet werden muss.
\item RTP setzt auf UDP auf, und wurde gerade für Streaminganwendungen
  konzipiert. Verschiedene RTP-Standards definieren wie
  Multimediadaten in UDP-Pakete verpackt werden sollen. Zusätzlich
  definiert RTP ein Feedback-Protokoll namens RTCP, mit dem der
  RTP-Server periodische Kontrollanfragen an seine Empfän\-ger schickt,
  um z. B. die Auslastung der Verbindung abzufragen.  Mit
  diesen Informationen kann der Server dann den Datenstrom anpassen,
  um eine bessere Übermittlung der Daten zu erreichen. In den RFCs
  2250 und 3119 wird beschrieben, wie man MP3-Daten über RTP streamen
  kann.
\end{itemize}

\subsubsection{Ver\-zö\-ge\-run\-gen}

Bei einem paketorientierten Netzwerk kann es zu mehreren unerwünschten
Nebenwirkungen kommen, die die Qualität eines Audiodatenstromes
erheblich beeinflussen können:
\begin{itemize}
\item Aufgrund eines Pufferüberlaufs in einer Netzwerkkomponente
  (Router, Switch) kann es zu Paketverlusten kommen. Einzelne
  verschickte Pakete erreichen nicht ihr Ziel.
\item Es kann zu Ver\-zö\-ge\-run\-gen kommen, und sogar zu eine Umordnung in
  der Paketreihenfolge, wenn einzelne Pakete über verschiedene Routen
  weitergeleitet werden.
\end{itemize}

% Delay
% QOS, Buffering
Da das IP-Protokoll keine Übertragungszeiten garantiert, sind
Ver\-zö\-ge\-run\-gen in jedem der in \ref{sub:verfahren} vorgestellten
Verfahren möglich.  Als Folge dieser Ver\-zö\-ge\-run\-gen kommt es meistens
zu Aussetzern in der Wiedergabe der Audiodaten. Bei radioähnlichen
Anwendungen lässt sich dieses Problem durch Puffern der eingehenden
Audiodaten in einen Cache in begrenztem Maße lösen. Allerdings ist das
Puffern von einkommenden Daten in Anwendungsfällen, die eine
Echtzeitübertragung der Audiodaten vorraussetzen, wie
Internet-Te\-le\-pho\-nie, nicht möglich, da eine Verzögerung bei der
Übertragung von Telefongesprächen nicht annehmbar ist. Eine andere
Möglichkeit, das Ver\-zö\-ge\-rungs\-pro\-blem zu lösen, ist die Einführung von
Quality-of-Service-Verfahren.  In einem solchen Fall werden IP-Pakete
verschiedenen Prioritätsklassen zugeordnet, mit denen die
Router eine verzögerungsfreie Verbindung gewährleisten können.

Wir setzen in dieser Arbeit eine radioähnliche Anwendung voraus, und
verwenden keine QOS-Verfahren.

\subsubsection{Paketverluste}
\label{paketverluste}
% Packetloss
Bei der Übertragung der Audiodaten kann es zu einem Verlust der
gesendeten Paketen kommen. Bei bestimmten Anwendungen sind fehlende
Pakete auf Empfän\-gerseite fatal, weil der Datenstrom nicht mehr
verarbeitet werden kann. MP3 kann allerdings bei dem Verlust von
beliebig vielen Frames weiter entschlüsselt werden, so dass es bei
Paketverlusten nur zu Aussetzern in der Wiedergabe der Audiodaten
kommt.

\begin{figure}[htbp]
  \centering
  \includegraphics[scale=0.43]{interleaving}
  \label{pic:interleaving}
  \caption{Spreizen von Paketen}
\end{figure}

% Interleaving
Die Korrelation von Paketverlusten kann benutzt werden, um die
Auswirkung von Paketverlusten zu minimieren.  Aufeinanderfolgende
Datengruppen (in unserem Fall MP3-Frames) können auf nicht
aufeinanderfolgende Pakete ``gespreizt'' werden
(siehe Abbildung \ref{pic:interleaving}). Bei einem Verlust von
mehreren Paketen kommt es dann nicht mehr zu einem langem Aussetzer in
der Wiedergabe, sondern zu mehreren kleinen Unterbrechungen, was für
den Hörer wesentlich angenehmer ist.

% FEC
Um eine Verschlechterung des Audiostroms bei Paketverlusten ganz zu
vermeiden, und nicht nur die Aussetzer für den Hörer ``angenehmer'' zu
gestalten, können Daten redundant verschickt werden. Die eleganteste
Lösung ist die Verwendung eines Vorwärtsfehlerkorrektur-Verfahrens
(Forward Error Correction). Aus $n$ zu versendenden Paketen werden $n
+ k$ Pakete gebildet, die alle übertragen werden.  Die Empfangsseite
braucht nur $n$ Pakete von den $n+k$ gesendeten Paketen um die
Ursprungsdaten wieder herstellen. In dieser Studienarbeit wird ein
Verfahren beschrieben, mit dem FEC kodierte MP3-Daten übertragen
werden.  Dieses Verfahren wird ausführlich in den Kapiteln
\ref{sec:transcoding}, \ref{sec:fec} und \ref{sec:implementation}
beschrieben.

